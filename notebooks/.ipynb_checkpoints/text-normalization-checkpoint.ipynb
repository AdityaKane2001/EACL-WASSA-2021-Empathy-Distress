{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/eastwind/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import Utils\n",
    "#from utils.preprocess import Preprocess\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/eastwind/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/eastwind/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/eastwind/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/eastwind/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package brown to /home/eastwind/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# File of the class PreprocessText, containing various functions for text preprocessing\n",
    "# File: preprocess.py\n",
    "# Author: Atharva Kulkarni\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import words, wordnet, brown\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import unicodedata\n",
    "from pycontractions import Contractions\n",
    "from autocorrect import Speller\n",
    "from utils import Utils\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('words')\n",
    "nltk.download('brown')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Preprocess():\n",
    "    \"\"\"\" Class containing various helper functions \"\"\"   \n",
    "    \n",
    "    \n",
    "    # -------------------------------------------- Class Constructor --------------------------------------------\n",
    "    \n",
    "    def __init__(self, mode=\"normalize\", contractions_model_path=\"/home/eastwind/word-embeddings/word2vec/GoogleNews-vectors-negative300.bin\"):\n",
    "        \"\"\" Class Constructor\n",
    "        @param contractions_model_path (str): model to be loaded for contractions expansion.\n",
    "        \"\"\"\n",
    "        self.utils = Utils()\n",
    "        self.stop_words = stopwords.words('english')\n",
    "        self.wordnet_lemmatizer = WordNetLemmatizer()\n",
    "        self.speller = Speller(lang='en')\n",
    "        self.wordlist = set(words.words()).union(set(wordnet.words()), set(brown.words()))\n",
    "        self.nouns = ['NNP', 'NNPS']\n",
    "        self.nlp = spacy.load('en_core_web_sm')\n",
    "        if mode == \"normalize\":\n",
    "            self.cont = Contractions(contractions_model_path)\n",
    "            self.cont.load_models()\n",
    "            \n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "       \n",
    "     \n",
    "    # -------------------------------------------- Function to expand contractions --------------------------------------------\n",
    "    \n",
    "    def expand_contractions(self, text):\n",
    "        \"\"\" Function to expand contractions\n",
    "        @param text (str): input text to euxpand contractions.\n",
    "        return text (str): Contraction expanded text.\n",
    "        \"\"\"\n",
    "        text = list(self.cont.expand_texts([text], precise=True))[0]\n",
    "        return text\n",
    "    \n",
    "      \n",
    "    \n",
    "    \n",
    "    # -------------------------------------------- Function to Correct Spellings --------------------------------------------\n",
    "       \n",
    "    def correct_spelling(self, word, pos):\n",
    "        \"\"\" Function to autocorrect words\n",
    "        @param word (str): misspelled words\n",
    "        @param proper_noun (list): list of proper nouns to ignore\n",
    "        return corrected word\n",
    "\n",
    "        \"\"\"\n",
    "        if word.lower() in self.wordlist or pos in self.nouns:\n",
    "            return word\n",
    "        else:\n",
    "            return self.speller(word.lower())\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    # --------------------------------------- Remove Wordplay ---------------------------------------\n",
    "    \n",
    "    def remove_wordplay(self, word, pos):\n",
    "        pattern = re.compile(r\"(\\w*)(\\w)\\2(\\w*)\")\n",
    "        substitution_pattern = r\"\\1\\2\\3\"\n",
    "        while True:\n",
    "            if word.lower() in self.wordlist or pos in self.nouns:\n",
    "                return word\n",
    "            new_word = pattern.sub(substitution_pattern, word)\n",
    "            if new_word != word:\n",
    "                word = new_word\n",
    "                continue\n",
    "            else:\n",
    "                return new_word\n",
    "                \n",
    "                \n",
    "                \n",
    "                    \n",
    "    # -------------------------------------------- Function to normalize input text --------------------------------------------\n",
    "    \n",
    "    def normalize_text(self, text):\n",
    "        \"\"\" Function to normalzie text inputs.\n",
    "        @param text (str): Input text.\n",
    "        \"\"\"\n",
    "        # Adding space for all puntuation marks\n",
    "        text = re.sub(r\"([\\w/'+$\\s-]+|[^\\w/'+$\\s-]+)\\s*\", r\"\\1 \", text)\n",
    "\n",
    "        # Remove accented words\n",
    "        text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "\n",
    "        # Remove long spaces\n",
    "        text = re.sub(r'^\\s*|\\s\\s*', ' ', text).strip()\n",
    "\n",
    "        tokenized_text = text.split()\n",
    "        \n",
    "        abbr_dict = self.utils.get_dict(\"/home/eastwind/PycharmProjects/WASSA-2021-Shared-Task/resources/custom-dictionaries/social-media-abbreviations.csv\", key_column=\"acronym\", value_column=\"full_form\")\n",
    "        for i in range(len(tokenized_text)):\n",
    "            x = re.sub(r'[^\\w\\s]', '', tokenized_text[i]).lower()\n",
    "            \n",
    "            # Expand acronyms\n",
    "            if x in abbr_dict.keys():\n",
    "                tokenized_text[i] = abbr_dict[x]\n",
    "\n",
    "            # Expand contracitons\n",
    "            tokenized_text[i] = self.expand_contractions(tokenized_text[i])    \n",
    "        \n",
    "        text = \" \".join([word for word in tokenized_text])\n",
    "        text = self.nlp(text)\n",
    "\n",
    "        # Remove wordplay\n",
    "        text = \" \".join([self.remove_wordplay(word.text, word.tag_) for word in text])\n",
    "        \n",
    "        # Correct Spellings\n",
    "        text = self.nlp(text)\n",
    "        text = \" \".join([self.correct_spelling(word.text, word.tag_) for word in text])\n",
    "        #text = self.speller(text)\n",
    "        return text\n",
    "        \n",
    "\n",
    "        \n",
    "      \n",
    "    # -------------------------------------------- Function to Normalize corpus --------------------------------------------\n",
    "        \n",
    "    def normalize_corpus(self, df, column_name):\n",
    "        \"\"\" Function to normalize corpus.\n",
    "        @param corpus (list): corpus list.\n",
    "        @param column_name (str): name of column to normalize.\n",
    "        \"\"\"\n",
    "        df[column_name] = df[column_name].apply(lambda text: self.normalize_text(text))\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # -------------------------------------------- Function to clean text --------------------------------------------\n",
    "        \n",
    "    def clean_text(self, text, remove_stopwords=True, lemmatize=True):\n",
    "        \"\"\" Function to clean text\n",
    "        @param text (str): text to be cleaned\n",
    "        @param remove_stopwords (bool): To remove stopwords or not.\n",
    "        @param lemmatize (bool): to lemmatize or not.\n",
    "        \"\"\"\n",
    "        # Remove emails \n",
    "        text = re.sub('\\S*@\\S*\\s?', '', text)\n",
    "        \n",
    "        # Remove new line characters \n",
    "        text = re.sub('\\s+', ' ', text) \n",
    "        \n",
    "        # Remove distracting single quotes \n",
    "        text = re.sub(\"\\'\", '', text)\n",
    "\n",
    "        # Remove puntuations and numbers\n",
    "        text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "\n",
    "        # Remove single characters\n",
    "        text = re.sub('\\s+[a-zA-Z]\\s+^I', ' ', text)\n",
    "        \n",
    "        # remove multiple spaces\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        text = text.lower()\n",
    "\n",
    "        if not remove_stopwords and not lemmatize:\n",
    "            return text\n",
    "\n",
    "        # Remove unncecessay stopwords\n",
    "        if remove_stopwords:\n",
    "            text = word_tokenize(text)\n",
    "            text = \" \".join([word for word in text if word not in self.stop_words])\n",
    "        \n",
    "        # Word lemmatization\n",
    "        if lemmatize:\n",
    "            text = self.nlp(text)\n",
    "            lemmatized_text = []\n",
    "            for word in text:\n",
    "                if word.lemma_.isalpha():\n",
    "                    if word.lemma_ != '-PRON-':\n",
    "                        lemmatized_text.append(word.lemma_.lower())\n",
    "                    # else:\n",
    "                        # lemmatized_text.append(word.lower())\n",
    "            text = \" \".join([word.lower() for word in lemmatized_text])\n",
    "                \n",
    "        return text\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.5 s, sys: 5.45 s, total: 45 s\n",
      "Wall time: 1min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "utils = Utils()\n",
    "pre = Preprocess(mode=\"normalize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.5 ms, sys: 0 ns, total: 9.5 ms\n",
      "Wall time: 56 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(525, 1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "emo_data = utils.read_data(\"../dataset/test/gold_standard_test_EMO.tsv\")\n",
    "emo_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24 ms, sys: 0 ns, total: 24 ms\n",
      "Wall time: 463 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(525, 18)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "data = utils.read_data(\"../dataset/test/messages_test_features_ready_for_WS.tsv\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(525, 19)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['gold_emotion'] = emo_data.emotion.values.tolist()\n",
    "# data['gold_empathy'] = emo_data.empathy.values.tolist()\n",
    "# data['gold_distress'] = emo_data.distress.values.tolist()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This isn't very surprising at all, is it? Another one of Putin's bodies. I like how it's just a thing that we expect to happen, and no one really cares very much except as a minor blip on the news. It's just expected, and the fact that people in our own government have an association with people who operate like this is largely going to be gotten away with. What do you think?\""
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_no = 111\n",
    "data.essay.values.tolist()[post_no]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.7 s, sys: 71.4 ms, total: 17.8 s\n",
      "Wall time: 19.6 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_id</th>\n",
       "      <th>response_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>essay</th>\n",
       "      <th>gender</th>\n",
       "      <th>education</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>personality_conscientiousness</th>\n",
       "      <th>personality_openess</th>\n",
       "      <th>personality_extraversion</th>\n",
       "      <th>personality_agreeableness</th>\n",
       "      <th>personality_stability</th>\n",
       "      <th>iri_perspective_taking</th>\n",
       "      <th>iri_personal_distress</th>\n",
       "      <th>iri_fantasy</th>\n",
       "      <th>iri_empathatic_concern</th>\n",
       "      <th>gold_emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R_2qabL3aLPfRMyA1_1</td>\n",
       "      <td>R_2qabL3aLPfRMyA1</td>\n",
       "      <td>17</td>\n",
       "      <td>Hello Friend , i am writing to you as regards ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.714</td>\n",
       "      <td>2.857</td>\n",
       "      <td>2.571</td>\n",
       "      <td>3.429</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R_2qabL3aLPfRMyA1_2</td>\n",
       "      <td>R_2qabL3aLPfRMyA1</td>\n",
       "      <td>164</td>\n",
       "      <td>Hello friend i will like to tell you that Indi...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.714</td>\n",
       "      <td>2.857</td>\n",
       "      <td>2.571</td>\n",
       "      <td>3.429</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R_2qabL3aLPfRMyA1_3</td>\n",
       "      <td>R_2qabL3aLPfRMyA1</td>\n",
       "      <td>196</td>\n",
       "      <td>Hello friend I will like to let you know Leona...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.714</td>\n",
       "      <td>2.857</td>\n",
       "      <td>2.571</td>\n",
       "      <td>3.429</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R_2qabL3aLPfRMyA1_4</td>\n",
       "      <td>R_2qabL3aLPfRMyA1</td>\n",
       "      <td>259</td>\n",
       "      <td>Hello friend , I will like to tell you Qatar l...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.714</td>\n",
       "      <td>2.857</td>\n",
       "      <td>2.571</td>\n",
       "      <td>3.429</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R_2qabL3aLPfRMyA1_5</td>\n",
       "      <td>R_2qabL3aLPfRMyA1</td>\n",
       "      <td>361</td>\n",
       "      <td>Dear friend , I will like to know that Trump s...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.714</td>\n",
       "      <td>2.857</td>\n",
       "      <td>2.571</td>\n",
       "      <td>3.429</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>R_1gShpZuf35KXreS_1</td>\n",
       "      <td>R_1gShpZuf35KXreS</td>\n",
       "      <td>73</td>\n",
       "      <td>Hey , I have always liked Billy Bob Thornton a...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.143</td>\n",
       "      <td>3.286</td>\n",
       "      <td>4.429</td>\n",
       "      <td>3.571</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>R_1gShpZuf35KXreS_2</td>\n",
       "      <td>R_1gShpZuf35KXreS</td>\n",
       "      <td>164</td>\n",
       "      <td>The fact that Donald Trump just peaced out of ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.143</td>\n",
       "      <td>3.286</td>\n",
       "      <td>4.429</td>\n",
       "      <td>3.571</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>R_1gShpZuf35KXreS_3</td>\n",
       "      <td>R_1gShpZuf35KXreS</td>\n",
       "      <td>182</td>\n",
       "      <td>I am not okay ! How can anyone harm something ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.143</td>\n",
       "      <td>3.286</td>\n",
       "      <td>4.429</td>\n",
       "      <td>3.571</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>R_1gShpZuf35KXreS_4</td>\n",
       "      <td>R_1gShpZuf35KXreS</td>\n",
       "      <td>260</td>\n",
       "      <td>I do not know anything outside of this article...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.143</td>\n",
       "      <td>3.286</td>\n",
       "      <td>4.429</td>\n",
       "      <td>3.571</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>R_1gShpZuf35KXreS_5</td>\n",
       "      <td>R_1gShpZuf35KXreS</td>\n",
       "      <td>358</td>\n",
       "      <td>Honestly , this man is the epitome of everythi...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.143</td>\n",
       "      <td>3.286</td>\n",
       "      <td>4.429</td>\n",
       "      <td>3.571</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>525 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              message_id        response_id  article_id  \\\n",
       "0    R_2qabL3aLPfRMyA1_1  R_2qabL3aLPfRMyA1          17   \n",
       "1    R_2qabL3aLPfRMyA1_2  R_2qabL3aLPfRMyA1         164   \n",
       "2    R_2qabL3aLPfRMyA1_3  R_2qabL3aLPfRMyA1         196   \n",
       "3    R_2qabL3aLPfRMyA1_4  R_2qabL3aLPfRMyA1         259   \n",
       "4    R_2qabL3aLPfRMyA1_5  R_2qabL3aLPfRMyA1         361   \n",
       "..                   ...                ...         ...   \n",
       "520  R_1gShpZuf35KXreS_1  R_1gShpZuf35KXreS          73   \n",
       "521  R_1gShpZuf35KXreS_2  R_1gShpZuf35KXreS         164   \n",
       "522  R_1gShpZuf35KXreS_3  R_1gShpZuf35KXreS         182   \n",
       "523  R_1gShpZuf35KXreS_4  R_1gShpZuf35KXreS         260   \n",
       "524  R_1gShpZuf35KXreS_5  R_1gShpZuf35KXreS         358   \n",
       "\n",
       "                                                 essay  gender  education  \\\n",
       "0    Hello Friend , i am writing to you as regards ...     2.0        6.0   \n",
       "1    Hello friend i will like to tell you that Indi...     2.0        6.0   \n",
       "2    Hello friend I will like to let you know Leona...     2.0        6.0   \n",
       "3    Hello friend , I will like to tell you Qatar l...     2.0        6.0   \n",
       "4    Dear friend , I will like to know that Trump s...     2.0        6.0   \n",
       "..                                                 ...     ...        ...   \n",
       "520  Hey , I have always liked Billy Bob Thornton a...     2.0        4.0   \n",
       "521  The fact that Donald Trump just peaced out of ...     2.0        4.0   \n",
       "522  I am not okay ! How can anyone harm something ...     2.0        4.0   \n",
       "523  I do not know anything outside of this article...     2.0        4.0   \n",
       "524  Honestly , this man is the epitome of everythi...     2.0        4.0   \n",
       "\n",
       "     race   age    income  personality_conscientiousness  personality_openess  \\\n",
       "0     3.0  22.0  100000.0                            5.5                  4.5   \n",
       "1     3.0  22.0  100000.0                            5.5                  4.5   \n",
       "2     3.0  22.0  100000.0                            5.5                  4.5   \n",
       "3     3.0  22.0  100000.0                            5.5                  4.5   \n",
       "4     3.0  22.0  100000.0                            5.5                  4.5   \n",
       "..    ...   ...       ...                            ...                  ...   \n",
       "520   1.0  28.0   21000.0                            7.0                  5.0   \n",
       "521   1.0  28.0   21000.0                            7.0                  5.0   \n",
       "522   1.0  28.0   21000.0                            7.0                  5.0   \n",
       "523   1.0  28.0   21000.0                            7.0                  5.0   \n",
       "524   1.0  28.0   21000.0                            7.0                  5.0   \n",
       "\n",
       "     personality_extraversion  personality_agreeableness  \\\n",
       "0                         3.5                        6.0   \n",
       "1                         3.5                        6.0   \n",
       "2                         3.5                        6.0   \n",
       "3                         3.5                        6.0   \n",
       "4                         3.5                        6.0   \n",
       "..                        ...                        ...   \n",
       "520                       1.0                        5.0   \n",
       "521                       1.0                        5.0   \n",
       "522                       1.0                        5.0   \n",
       "523                       1.0                        5.0   \n",
       "524                       1.0                        5.0   \n",
       "\n",
       "     personality_stability  iri_perspective_taking  iri_personal_distress  \\\n",
       "0                      6.0                   3.714                  2.857   \n",
       "1                      6.0                   3.714                  2.857   \n",
       "2                      6.0                   3.714                  2.857   \n",
       "3                      6.0                   3.714                  2.857   \n",
       "4                      6.0                   3.714                  2.857   \n",
       "..                     ...                     ...                    ...   \n",
       "520                    3.5                   4.143                  3.286   \n",
       "521                    3.5                   4.143                  3.286   \n",
       "522                    3.5                   4.143                  3.286   \n",
       "523                    3.5                   4.143                  3.286   \n",
       "524                    3.5                   4.143                  3.286   \n",
       "\n",
       "     iri_fantasy  iri_empathatic_concern gold_emotion  \n",
       "0          2.571                   3.429      sadness  \n",
       "1          2.571                   3.429          joy  \n",
       "2          2.571                   3.429      neutral  \n",
       "3          2.571                   3.429      neutral  \n",
       "4          2.571                   3.429      neutral  \n",
       "..           ...                     ...          ...  \n",
       "520        4.429                   3.571          joy  \n",
       "521        4.429                   3.571        anger  \n",
       "522        4.429                   3.571      sadness  \n",
       "523        4.429                   3.571      sadness  \n",
       "524        4.429                   3.571        anger  \n",
       "\n",
       "[525 rows x 19 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "normalized_data = pre.normalize_corpus(data.copy(), column_name=\"essay\")\n",
    "normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This is not very surprising at all , is it ? Another one of Putin 's bodies . I like how it is just a thing that we expect to happen , and no one really cares very much except as a minor blip on the news . it is just expected , and the fact that people in our own government have an association with people who operate like this is largely going to be gotten away with . What do you think ?\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_data.essay.values.tolist()[post_no]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1860, 27)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalized_data['gold_empathy_bin'] = normalized_data.gold_empathy.apply(lambda x: 1 if x>=4.0 else 0)\n",
    "# normalized_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1860, 28)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalized_data['gold_distress_bin'] = normalized_data.gold_distress.apply(lambda x: 1 if x>=4.0 else 0)\n",
    "# normalized_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data.to_csv(\"../dataset/test/test-data-normalized.csv\", sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_id</th>\n",
       "      <th>response_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>essay</th>\n",
       "      <th>gender</th>\n",
       "      <th>education</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>personality_conscientiousness</th>\n",
       "      <th>personality_openess</th>\n",
       "      <th>personality_extraversion</th>\n",
       "      <th>personality_agreeableness</th>\n",
       "      <th>personality_stability</th>\n",
       "      <th>iri_perspective_taking</th>\n",
       "      <th>iri_personal_distress</th>\n",
       "      <th>iri_fantasy</th>\n",
       "      <th>iri_empathatic_concern</th>\n",
       "      <th>gold_emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R_2qabL3aLPfRMyA1_1</td>\n",
       "      <td>R_2qabL3aLPfRMyA1</td>\n",
       "      <td>17</td>\n",
       "      <td>Hello Friend , i am writing to you as regards ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.714</td>\n",
       "      <td>2.857</td>\n",
       "      <td>2.571</td>\n",
       "      <td>3.429</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R_2qabL3aLPfRMyA1_2</td>\n",
       "      <td>R_2qabL3aLPfRMyA1</td>\n",
       "      <td>164</td>\n",
       "      <td>Hello friend i will like to tell you that Indi...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.714</td>\n",
       "      <td>2.857</td>\n",
       "      <td>2.571</td>\n",
       "      <td>3.429</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R_2qabL3aLPfRMyA1_3</td>\n",
       "      <td>R_2qabL3aLPfRMyA1</td>\n",
       "      <td>196</td>\n",
       "      <td>Hello friend I will like to let you know Leona...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.714</td>\n",
       "      <td>2.857</td>\n",
       "      <td>2.571</td>\n",
       "      <td>3.429</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R_2qabL3aLPfRMyA1_4</td>\n",
       "      <td>R_2qabL3aLPfRMyA1</td>\n",
       "      <td>259</td>\n",
       "      <td>Hello friend , I will like to tell you Qatar l...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.714</td>\n",
       "      <td>2.857</td>\n",
       "      <td>2.571</td>\n",
       "      <td>3.429</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R_2qabL3aLPfRMyA1_5</td>\n",
       "      <td>R_2qabL3aLPfRMyA1</td>\n",
       "      <td>361</td>\n",
       "      <td>Dear friend , I will like to know that Trump s...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.714</td>\n",
       "      <td>2.857</td>\n",
       "      <td>2.571</td>\n",
       "      <td>3.429</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>R_1gShpZuf35KXreS_1</td>\n",
       "      <td>R_1gShpZuf35KXreS</td>\n",
       "      <td>73</td>\n",
       "      <td>Hey , I have always liked Billy Bob Thornton a...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.143</td>\n",
       "      <td>3.286</td>\n",
       "      <td>4.429</td>\n",
       "      <td>3.571</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>R_1gShpZuf35KXreS_2</td>\n",
       "      <td>R_1gShpZuf35KXreS</td>\n",
       "      <td>164</td>\n",
       "      <td>The fact that Donald Trump just peaced out of ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.143</td>\n",
       "      <td>3.286</td>\n",
       "      <td>4.429</td>\n",
       "      <td>3.571</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>R_1gShpZuf35KXreS_3</td>\n",
       "      <td>R_1gShpZuf35KXreS</td>\n",
       "      <td>182</td>\n",
       "      <td>I am not okay ! How can anyone harm something ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.143</td>\n",
       "      <td>3.286</td>\n",
       "      <td>4.429</td>\n",
       "      <td>3.571</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>R_1gShpZuf35KXreS_4</td>\n",
       "      <td>R_1gShpZuf35KXreS</td>\n",
       "      <td>260</td>\n",
       "      <td>I do not know anything outside of this article...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.143</td>\n",
       "      <td>3.286</td>\n",
       "      <td>4.429</td>\n",
       "      <td>3.571</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>R_1gShpZuf35KXreS_5</td>\n",
       "      <td>R_1gShpZuf35KXreS</td>\n",
       "      <td>358</td>\n",
       "      <td>Honestly , this man is the epitome of everythi...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.143</td>\n",
       "      <td>3.286</td>\n",
       "      <td>4.429</td>\n",
       "      <td>3.571</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>525 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              message_id        response_id  article_id  \\\n",
       "0    R_2qabL3aLPfRMyA1_1  R_2qabL3aLPfRMyA1          17   \n",
       "1    R_2qabL3aLPfRMyA1_2  R_2qabL3aLPfRMyA1         164   \n",
       "2    R_2qabL3aLPfRMyA1_3  R_2qabL3aLPfRMyA1         196   \n",
       "3    R_2qabL3aLPfRMyA1_4  R_2qabL3aLPfRMyA1         259   \n",
       "4    R_2qabL3aLPfRMyA1_5  R_2qabL3aLPfRMyA1         361   \n",
       "..                   ...                ...         ...   \n",
       "520  R_1gShpZuf35KXreS_1  R_1gShpZuf35KXreS          73   \n",
       "521  R_1gShpZuf35KXreS_2  R_1gShpZuf35KXreS         164   \n",
       "522  R_1gShpZuf35KXreS_3  R_1gShpZuf35KXreS         182   \n",
       "523  R_1gShpZuf35KXreS_4  R_1gShpZuf35KXreS         260   \n",
       "524  R_1gShpZuf35KXreS_5  R_1gShpZuf35KXreS         358   \n",
       "\n",
       "                                                 essay  gender  education  \\\n",
       "0    Hello Friend , i am writing to you as regards ...     2.0        6.0   \n",
       "1    Hello friend i will like to tell you that Indi...     2.0        6.0   \n",
       "2    Hello friend I will like to let you know Leona...     2.0        6.0   \n",
       "3    Hello friend , I will like to tell you Qatar l...     2.0        6.0   \n",
       "4    Dear friend , I will like to know that Trump s...     2.0        6.0   \n",
       "..                                                 ...     ...        ...   \n",
       "520  Hey , I have always liked Billy Bob Thornton a...     2.0        4.0   \n",
       "521  The fact that Donald Trump just peaced out of ...     2.0        4.0   \n",
       "522  I am not okay ! How can anyone harm something ...     2.0        4.0   \n",
       "523  I do not know anything outside of this article...     2.0        4.0   \n",
       "524  Honestly , this man is the epitome of everythi...     2.0        4.0   \n",
       "\n",
       "     race   age    income  personality_conscientiousness  personality_openess  \\\n",
       "0     3.0  22.0  100000.0                            5.5                  4.5   \n",
       "1     3.0  22.0  100000.0                            5.5                  4.5   \n",
       "2     3.0  22.0  100000.0                            5.5                  4.5   \n",
       "3     3.0  22.0  100000.0                            5.5                  4.5   \n",
       "4     3.0  22.0  100000.0                            5.5                  4.5   \n",
       "..    ...   ...       ...                            ...                  ...   \n",
       "520   1.0  28.0   21000.0                            7.0                  5.0   \n",
       "521   1.0  28.0   21000.0                            7.0                  5.0   \n",
       "522   1.0  28.0   21000.0                            7.0                  5.0   \n",
       "523   1.0  28.0   21000.0                            7.0                  5.0   \n",
       "524   1.0  28.0   21000.0                            7.0                  5.0   \n",
       "\n",
       "     personality_extraversion  personality_agreeableness  \\\n",
       "0                         3.5                        6.0   \n",
       "1                         3.5                        6.0   \n",
       "2                         3.5                        6.0   \n",
       "3                         3.5                        6.0   \n",
       "4                         3.5                        6.0   \n",
       "..                        ...                        ...   \n",
       "520                       1.0                        5.0   \n",
       "521                       1.0                        5.0   \n",
       "522                       1.0                        5.0   \n",
       "523                       1.0                        5.0   \n",
       "524                       1.0                        5.0   \n",
       "\n",
       "     personality_stability  iri_perspective_taking  iri_personal_distress  \\\n",
       "0                      6.0                   3.714                  2.857   \n",
       "1                      6.0                   3.714                  2.857   \n",
       "2                      6.0                   3.714                  2.857   \n",
       "3                      6.0                   3.714                  2.857   \n",
       "4                      6.0                   3.714                  2.857   \n",
       "..                     ...                     ...                    ...   \n",
       "520                    3.5                   4.143                  3.286   \n",
       "521                    3.5                   4.143                  3.286   \n",
       "522                    3.5                   4.143                  3.286   \n",
       "523                    3.5                   4.143                  3.286   \n",
       "524                    3.5                   4.143                  3.286   \n",
       "\n",
       "     iri_fantasy  iri_empathatic_concern gold_emotion  \n",
       "0          2.571                   3.429      sadness  \n",
       "1          2.571                   3.429          joy  \n",
       "2          2.571                   3.429      neutral  \n",
       "3          2.571                   3.429      neutral  \n",
       "4          2.571                   3.429      neutral  \n",
       "..           ...                     ...          ...  \n",
       "520        4.429                   3.571          joy  \n",
       "521        4.429                   3.571        anger  \n",
       "522        4.429                   3.571      sadness  \n",
       "523        4.429                   3.571      sadness  \n",
       "524        4.429                   3.571        anger  \n",
       "\n",
       "[525 rows x 19 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../dataset/test/test-data-normalized.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
