{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from utils.utils import Utils\n",
    "from utils.preprocess import Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "utils = Utils()\n",
    "pre = Preprocess(mode=\"clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_correlation(y_true, y_pred):\n",
    "        y_pred = y_pred.flatten()\n",
    "        y_true = y_true.flatten()\n",
    "        return pearsonr(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = utils.read_data(\"../dataset/train/train-final.csv\")\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_weights = utils.get_dict(\"../resources/word-weights/empathy_word_weights.csv\",\n",
    "                             key_column=\"words\",\n",
    "                             value_column=\"weights\")\n",
    "len(word_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_essay = [pre.clean_text(text, remove_stopwords=False, lemmatize=True) for text in train_data.essay.values.tolist()]\n",
    "train_essay_empathy_scores = utils.get_essay_empathy_distress_scores(train_essay,\n",
    "                                                                     word_weights)\n",
    "train_essay_empathy_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_essay_empathy_scores[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_empathy = np.reshape(train_data.gold_empathy.values.tolist(), (len(train_data.gold_empathy.values.tolist()), 1))\n",
    "train_empathy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cor = compute_correlation(train_empathy, train_essay_empathy_scores)\n",
    "train_cor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dev Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = utils.read_data(\"../dataset/dev/dev-final.csv\")\n",
    "print(dev_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_essay = [pre.clean_text(text, remove_stopwords=False, lemmatize=True) for text in dev_data.essay.values.tolist()]\n",
    "dev_essay_empathy_scores = utils.get_essay_empathy_distress_scores(dev_essay,\n",
    "                                                                   word_weights)\n",
    "dev_essay_empathy_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_essay_empathy_scores[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_empathy = np.reshape(dev_data.gold_empathy.values.tolist(), (len(dev_data.gold_empathy.values.tolist()), 1))\n",
    "dev_empathy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_cor = compute_correlation(dev_empathy, dev_essay_empathy_scores)\n",
    "dev_cor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tan-Inverse Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arctan_word_weights = utils.get_dict(\"../resources/word-weights/empathy_word_weights.csv\",\n",
    "                             key_column=\"words\",\n",
    "                             value_column=\"weights-arctan\")\n",
    "len(arctan_word_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_essay = [pre.clean_text(text, remove_stopwords=False, lemmatize=True) for text in train_data.essay.values.tolist()]\n",
    "train_essay_empathy_scores = utils.get_essay_empathy_distress_scores(train_essay,\n",
    "                                                                     arctan_word_weights)\n",
    "train_essay_empathy_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_essay_empathy_scores[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_empathy = np.reshape(train_data.gold_empathy.values.tolist(), (len(train_data.gold_empathy.values.tolist()), 1))\n",
    "train_empathy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cor = compute_correlation(train_empathy, train_essay_empathy_scores)\n",
    "train_cor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dev Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_essay = [pre.clean_text(text, remove_stopwords=False, lemmatize=True) for text in dev_data.essay.values.tolist()]\n",
    "dev_essay_empathy_scores = utils.get_essay_empathy_distress_scores(dev_essay,\n",
    "                                                                   arctan_word_weights)\n",
    "dev_essay_empathy_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_essay_empathy_scores[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_empathy = np.reshape(dev_data.gold_empathy.values.tolist(), (len(dev_data.gold_empathy.values.tolist()), 1))\n",
    "dev_empathy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_cor = compute_correlation(dev_empathy, dev_essay_empathy_scores)\n",
    "dev_cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
