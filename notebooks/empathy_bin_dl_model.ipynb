{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zgDaGsqkOp9f"
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "import pandas, xgboost, numpy, textblob, string\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-uTS4TyOrNr"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OxCV_RckHw3a",
    "outputId": "c89120a3-112e-4b4b-fc3f-5f0560390cb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               message_id  ... iri_empathatic_concern\n",
      "0     R_1hGrPtWM4SumG0U_1  ...                  4.000\n",
      "1     R_1hGrPtWM4SumG0U_2  ...                  4.000\n",
      "2     R_1hGrPtWM4SumG0U_3  ...                  4.000\n",
      "3     R_1hGrPtWM4SumG0U_4  ...                  4.000\n",
      "4     R_1hGrPtWM4SumG0U_5  ...                  4.000\n",
      "...                   ...  ...                    ...\n",
      "1855  R_DHy2Rcz9Hym8jgl_1  ...                  4.429\n",
      "1856  R_DHy2Rcz9Hym8jgl_2  ...                  4.429\n",
      "1857  R_DHy2Rcz9Hym8jgl_3  ...                  4.429\n",
      "1858  R_DHy2Rcz9Hym8jgl_4  ...                  4.429\n",
      "1859  R_DHy2Rcz9Hym8jgl_5  ...                  4.429\n",
      "\n",
      "[1860 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "#import data\n",
    "\n",
    "df = pd.read_csv (r'track-1-essay-empathy-train.csv')\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zmB3rYrEfEZ6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vv63ldzmfQTE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z56rqsJ6_-K7"
   },
   "outputs": [],
   "source": [
    "# split the dataset into training and validation datasets \n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(df['essay'], df['empathy_bin'], test_size=0.10,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x1XMZlOOHOCA"
   },
   "outputs": [],
   "source": [
    "max_length = max([len(s.split()) for s in df['essay']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NmBpTzwpHYuI",
    "outputId": "fd06c805-0fc1-4fe4-dbe0-63c0ffe11bf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163\n"
     ]
    }
   ],
   "source": [
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sFwUgyMkMwn1",
    "outputId": "2de20254-008e-4eaa-ecf5-3b4a1b2b1189"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.0897      0.016      -0.0571     ...  0.1559     -0.0254\n",
      "  -0.0259    ]\n",
      " [ 0.0495      0.0411      0.0041     ...  0.23710001 -0.0298\n",
      "  -0.0284    ]\n",
      " ...\n",
      " [ 0.0114     -0.0305     -0.0284     ...  0.2199     -0.2313\n",
      "   0.0016    ]\n",
      " [ 0.21969999 -0.1183     -0.0465     ...  0.0931     -0.0329\n",
      "   0.1121    ]\n",
      " [-0.3256      0.0255      0.0938     ... -0.0964      0.0724\n",
      "  -0.0605    ]]\n"
     ]
    }
   ],
   "source": [
    "# load the pre-trained word-embedding vectors \n",
    "embeddings_index = {}\n",
    "for i, line in enumerate(open('/content/drive/MyDrive/wiki-news-300d-1M.vec')):\n",
    "    values = line.split()\n",
    "    embeddings_index[values[0]] = numpy.asarray(values[1:], dtype='float32')\n",
    "\n",
    "# create a tokenizer \n",
    "token = text.Tokenizer()\n",
    "token.fit_on_texts(df['essay'])\n",
    "word_index = token.word_index\n",
    "\n",
    "vocab_size = len(token.word_index) + 1\n",
    "\n",
    "\n",
    "# convert text to sequence of tokens and pad them to ensure equal length vectors \n",
    "train_seq_x = sequence.pad_sequences(token.texts_to_sequences(train_x), maxlen=max_length)\n",
    "valid_seq_x = sequence.pad_sequences(token.texts_to_sequences(valid_x), maxlen=max_length)\n",
    "\n",
    "# create token-embedding mapping\n",
    "embedding_matrix = numpy.zeros((len(word_index) + 1, 300))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "print(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_QP51x3eHMZV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pXGwdDN6M0Po"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, GRU, GlobalMaxPooling1D\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f64tlnuCCGAg"
   },
   "outputs": [],
   "source": [
    "Embedding_dims = 300\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, Embedding_dims, weights=[embedding_matrix], input_length=max_length, trainable=True,))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "#model.add(GRU(units=64, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yRoe1r9NDGTD",
    "outputId": "12300104-610f-4f71-f1c3-983e582c4633"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 163, 300)          3017100   \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 301       \n",
      "=================================================================\n",
      "Total params: 3,017,401\n",
      "Trainable params: 3,017,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y2KoTqKmD5Sv",
    "outputId": "ebd7495e-0679-4d42-b876-bb0bb8e35da4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "14/14 - 2s - loss: 0.6960 - accuracy: 0.4898 - val_loss: 0.6979 - val_accuracy: 0.4677\n",
      "Epoch 2/20\n",
      "14/14 - 1s - loss: 0.6741 - accuracy: 0.6392 - val_loss: 0.6938 - val_accuracy: 0.5161\n",
      "Epoch 3/20\n",
      "14/14 - 1s - loss: 0.6568 - accuracy: 0.7503 - val_loss: 0.6905 - val_accuracy: 0.6129\n",
      "Epoch 4/20\n",
      "14/14 - 1s - loss: 0.6389 - accuracy: 0.8590 - val_loss: 0.6877 - val_accuracy: 0.5699\n",
      "Epoch 5/20\n",
      "14/14 - 1s - loss: 0.6217 - accuracy: 0.8990 - val_loss: 0.6858 - val_accuracy: 0.5806\n",
      "Epoch 6/20\n",
      "14/14 - 1s - loss: 0.6037 - accuracy: 0.8787 - val_loss: 0.6842 - val_accuracy: 0.5430\n",
      "Epoch 7/20\n",
      "14/14 - 1s - loss: 0.5845 - accuracy: 0.8990 - val_loss: 0.6790 - val_accuracy: 0.6237\n",
      "Epoch 8/20\n",
      "14/14 - 1s - loss: 0.5627 - accuracy: 0.9863 - val_loss: 0.6769 - val_accuracy: 0.5860\n",
      "Epoch 9/20\n",
      "14/14 - 1s - loss: 0.5411 - accuracy: 0.9875 - val_loss: 0.6723 - val_accuracy: 0.6183\n",
      "Epoch 10/20\n",
      "14/14 - 1s - loss: 0.5172 - accuracy: 0.9875 - val_loss: 0.6690 - val_accuracy: 0.6129\n",
      "Epoch 11/20\n",
      "14/14 - 1s - loss: 0.4914 - accuracy: 0.9892 - val_loss: 0.6642 - val_accuracy: 0.6129\n",
      "Epoch 12/20\n",
      "14/14 - 1s - loss: 0.4639 - accuracy: 0.9958 - val_loss: 0.6607 - val_accuracy: 0.6237\n",
      "Epoch 13/20\n",
      "14/14 - 1s - loss: 0.4361 - accuracy: 0.9970 - val_loss: 0.6557 - val_accuracy: 0.6022\n",
      "Epoch 14/20\n",
      "14/14 - 1s - loss: 0.4069 - accuracy: 0.9982 - val_loss: 0.6513 - val_accuracy: 0.6075\n",
      "Epoch 15/20\n",
      "14/14 - 1s - loss: 0.3782 - accuracy: 0.9982 - val_loss: 0.6474 - val_accuracy: 0.6022\n",
      "Epoch 16/20\n",
      "14/14 - 1s - loss: 0.3492 - accuracy: 0.9982 - val_loss: 0.6438 - val_accuracy: 0.5914\n",
      "Epoch 17/20\n",
      "14/14 - 1s - loss: 0.3211 - accuracy: 0.9988 - val_loss: 0.6396 - val_accuracy: 0.6129\n",
      "Epoch 18/20\n",
      "14/14 - 1s - loss: 0.2942 - accuracy: 0.9988 - val_loss: 0.6358 - val_accuracy: 0.6075\n",
      "Epoch 19/20\n",
      "14/14 - 1s - loss: 0.2687 - accuracy: 0.9994 - val_loss: 0.6321 - val_accuracy: 0.6183\n",
      "Epoch 20/20\n",
      "14/14 - 1s - loss: 0.2447 - accuracy: 0.9994 - val_loss: 0.6283 - val_accuracy: 0.6237\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9642bcc208>"
      ]
     },
     "execution_count": 75,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_seq_x, train_y, batch_size=128, epochs=20, validation_data=(valid_seq_x, valid_y), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pju7va4tEtFw",
    "outputId": "2d5ddc58-ee8d-4042-c01d-5d1f0e47bff1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   0.1930444\n",
      "1   0.82704175\n",
      "2   0.24878475\n",
      "3   0.13226953\n",
      "4   0.32381982\n",
      "5   0.34261495\n",
      "6   0.14369982\n",
      "7   0.21993467\n",
      "8   0.1511386\n",
      "9   0.58142936\n",
      "10   0.90013814\n",
      "11   0.83139455\n",
      "12   0.7888224\n",
      "13   0.82673717\n",
      "14   0.18677709\n",
      "15   0.87183034\n",
      "16   0.80852884\n",
      "17   0.13672954\n",
      "18   0.25953096\n",
      "19   0.12953767\n"
     ]
    }
   ],
   "source": [
    "y = model.predict(x=train_seq_x[:20])\n",
    "for i in range(len(y)):\n",
    "  #print()\n",
    "  print(i, ' ', y[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v-XiJtZSbZPP",
    "outputId": "d04aaa47-1199-4f14-8785-8e15b28eb025"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     1\n",
      "1     1\n",
      "2     0\n",
      "3     1\n",
      "4     1\n",
      "5     0\n",
      "6     0\n",
      "7     1\n",
      "8     0\n",
      "9     0\n",
      "10    1\n",
      "11    0\n",
      "12    1\n",
      "13    0\n",
      "14    1\n",
      "15    1\n",
      "16    1\n",
      "17    0\n",
      "18    1\n",
      "19    1\n",
      "Name: distress_bin, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['distress_bin'][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hxAuzvCnd3Kg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DWnKY_HgeFBi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "empathy_bin_dl_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
